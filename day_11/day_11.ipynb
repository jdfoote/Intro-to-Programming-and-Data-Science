{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and operationalization\n",
    "\n",
    "I'm going to introduce a dataset of vehicle crashes in Indiana, show how to import it into pandas, and give examples of a few ways of exploring this data.\n",
    "\n",
    "**Download the data from [here](https://github.com/jdfoote/Intro-to-Programming-and-Data-Science/blob/master/resources/data/aries_crash_data_2018_filtered.csv?raw=true)**. I created this CSV file from [this full dataset](https://hub.mph.in.gov/dataset/aries-crash-data-2007-2017/resource/cc90589c-72d8-4d92-a5fe-73254b555c73) by filtering out many of the columns to make it small enough to easily fit in memory.\n",
    "\n",
    "A description of the columns is [here](https://hub.mph.in.gov/dataset/aries-crash-data-2007-2017/resource/f61a5dcb-5ca3-485a-9ecf-cd3d8740dc9b?inner_span=True).\n",
    "\n",
    "Then, I want you to form groups of 2-4 where you identify a hypothesis about this data, brainstorm a visualization or set of visualizations that would give you insight into your hypothesis, and then try to create that visualization in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code downloads the CSV every time it's run.\n",
    "# Instead, you may want to download the CSV to your computer, and load it from there\n",
    "# You can use the same code, just change the path to where you download it\n",
    "raw_df = pd.read_csv('https://github.com/jdfoote/Intro-to-Programming-and-Data-Science/blob/master/resources/data/aries_crash_data_2018_filtered.csv?raw=true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding and Cleaning the data\n",
    "\n",
    "I always start by looking at the data to make sure things look reasonable and to figure out what we are looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like Gender and age and drug test results are all NA for the first few rows. Let's check how often they were recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the total number of rows\n",
    "len(raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it looks like the drug test column \"RESULTDRUGIND\" is going to be pretty useless. It's almost never recorded.\n",
    "\n",
    "It looks like age and gender are only recorded about half the time. Let's look a littel closer into the data and see if we can figure out what's going on.\n",
    "\n",
    "What does this data represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's still not totally clear what this data represents. From the description, we can see that the Individual MR Record refers to each incident, so let's so how many of them there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_df.INDIVIDUAL_MR_RECORD.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Far fewer than the total rows. Let's sort by that, and see if we can figure out more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.sort_values(\"INDIVIDUAL_MR_RECORD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at just one incident; it looks like the drivers, any injured passengers, and the owners are all listed (although no information is given about owners)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.loc[raw_df.INDIVIDUAL_MR_RECORD == 903070479,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if this is true more broadly. It seems like the \"Owner Vehicle\" rows just aren't going to be much use to us at all. Let's try to get a sense of how common they are, and if they really never contain information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_df[raw_df.PERSONTYPEDESCR == 'Owner Vehicle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df[raw_df.PERSONTYPEDESCR == 'Owner Vehicle'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like for the data we have here, the \"Owner Vehicle\" entries aren't giving us any extra information, so let's just remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = raw_df[raw_df.PERSONTYPEDESCR != 'Owner Vehicle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating measures from raw data\n",
    "\n",
    "It is very common that the raw data isn't in the form that you need it. You need to figure out how to transform it into something usable for the statistics and/or visualizations that you want to produce.\n",
    "\n",
    "In this case, I'm going to take the goal of understanding collisions. Each row of the data represents a person, not a collision, so if we visualized or analyzed the raw data, we could be misled, as collisions with more people would receive more weight.\n",
    "\n",
    "So, what we need to do is to build a dataset of accidents, with datetime, weather, number injured, and number killed.\n",
    "\n",
    "My suspicion, based on what I've seen so far, is that all of these are the same across each of the rows for a given collision. It is worth testing that assumption, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = raw_df.sort_values(['COLLDTE', 'COLLISION_TIME']).groupby(\"INDIVIDUAL_MR_RECORD\")\n",
    "\n",
    "# For example, this is a simple test of the number of unique weather descriptions per group.\n",
    "sum(grouped.WEATHERDESCR.nunique() > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see the same for number injured and number killed\n",
    "print(sum(grouped.INJUREDNMB.nunique() > 1))\n",
    "print(sum(grouped.DEADNMB.nunique() > 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can move forward with the assumption that just getting the first value is good enough for summarizing the accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first entry for each of these\n",
    "coll_df = pd.DataFrame({\"date\" : grouped.COLLDTE.first(),\n",
    "                        \"time\": grouped.COLLISION_TIME.first() + grouped.COLLISION_TIME_AM_PM.first(), \n",
    "                        \"injured\": grouped.INJUREDNMB.first(),\n",
    "                        \"deceased\": grouped.DEADNMB.first(),\n",
    "                        \"weather\": grouped.WEATHERDESCR.first(),\n",
    "                        \"accident_count\": 1\n",
    "                       })\n",
    "\n",
    "coll_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coll_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing our data\n",
    "\n",
    "We finally(!) have a dataset that we understand and that we can use in order to start to answer the questions we're interested in.\n",
    "\n",
    "As before, we need to get the date and time into a datetime object in the index.\n",
    "\n",
    "`pd.to_datetime` tries to convert a string into a datetime. I had to add a space in between the two columns to get it to work, but this does the trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_df.index = pd.to_datetime(coll_df.date + ' ' + coll_df.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the total number of accidents by month over 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_df.resample('M').accident_count.sum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how about the relationship between weather and accidents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_summary = coll_df.groupby('weather').accident_count.sum()\n",
    "weather_summary.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could we correct for how often weather appears?\n",
    "\n",
    "One simple way is to categorize each day by the weather that appears most often in accident reports. This obviously has some issues but it's the best we can probably do using just this data. What could be wise is to import another dataset which has historical weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_per_day = coll_df.groupby(coll_df.index.date).agg(\n",
    "    # Create a new column called weather which gets the modal weather for each day\n",
    "    weather = ('weather', lambda x: x.mode()),\n",
    "    # And accidents which is the number of accidents that day\n",
    "    accidents = ('accident_count', sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_per_day.groupby('weather').accidents.mean().plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. How would you create the above plot in Seaborn instead?\n",
    "\n",
    "2. Find a question that you'd like to answer with this data or the reddit data. Figure out how to filter/clean/group the data to produce the summary data that will help you to find that answer, and produce a visualization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
