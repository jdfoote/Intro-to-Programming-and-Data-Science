{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Statistics in Python\n",
    "\n",
    "I'm going to show you how to run some simple statistics using Python.\n",
    "\n",
    "In general, Python is very powerful for machine learning (e.g., scikit-learn, TensorFlow, etc.), while R is designed for statistics and cutting-edge statistical tools typically show up there first. That being said, all of the basic tools of a social science researcher are avaiable in Python.\n",
    "\n",
    "In this notebook, I show you how to run some basic statistical tests and models using the [scipy stats module](https://docs.scipy.org/doc/scipy/reference/stats.html). I am assuming that you already have a working knowledge of what these statistical tests do. I am just showing you how to perform them in Python.\n",
    "\n",
    "* Note: I personally do most of my statistical modeling in R, so I may be missing some of the tools that pure Python researchers would be aware of.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "I'm going to just create some random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = stats.norm.rvs(size = 100) # 100 random, normally distributed values\n",
    "X2 = stats.norm.rvs(size = 100)\n",
    "X3 = stats.norm.rvs(size = 100)\n",
    "group = np.random.choice(['A','B','C'], size=100)\n",
    "# Our outcome is influenced by X1, X2, and the group, plus some random noise\n",
    "Y = 1.5 * X1 - 2.3 * X2 + 3 * (group == 'A') + 1.2 * (group == 'B') + stats.norm.rvs(size = 100)\n",
    "\n",
    "# We can store these in a data frame\n",
    "df = pd.DataFrame({'X1':X1,\n",
    "                   'X2':X2,\n",
    "                   'X3': X3,\n",
    "                   'group':group,\n",
    "                   'Y':Y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate statistics\n",
    "\n",
    "There are lots of univariate statistics we can get - mean, median, quartiles, quantiles, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These all use numpy. This is the mean\n",
    "np.mean(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And this is how you do the same thing with data in a data frame.\n",
    "# All columns are numpy arrays underneath, so this first should work for\n",
    "# any of the statistics.\n",
    "\n",
    "# Numpy way\n",
    "np.mean(df.X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas also has a number of statistics built in, which you can apply directly\n",
    "df.X1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all columns\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is obviously great for doing grouping, which you often want for this\n",
    "# type of statistics. \"aggregate\" lets you get multiple statistics\n",
    "\n",
    "df.groupby('group').aggregate([np.mean, np.median])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can even write your own custom functions to aggregate\n",
    "\n",
    "def mean_plus_1(array):\n",
    "    array = array + 1\n",
    "    return np.mean(array)\n",
    "\n",
    "df.groupby('group').agg(mean_plus_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Get the median and the 25th percentile value for X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More built in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The describe function lists a number of these\n",
    "stats.describe(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This also works for dataframes, with a different set of stats\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-variate statistics\n",
    "\n",
    "### Correlations\n",
    "Scipy has both Pearson's correlation and Spearman's rank correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a64782663a63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# These 2 should not be correlated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# the first value returned is R, the second is the p-value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stats' is not defined"
     ]
    }
   ],
   "source": [
    "# These 2 should not be correlated. \n",
    "stats.pearsonr(X1, X2)\n",
    "# the first value returned is R, the second is the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These should be correlated, on the other hand\n",
    "stats.pearsonr(X1, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pandas, you can get a correlation matrix\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or just pass the columns you are interested in\n",
    "stats.pearsonr(df.X1, df.X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(X1, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(X1, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-tests\n",
    "\n",
    "T-tests test whether 2 distributions have the same mean.\n",
    "\n",
    "For our data, X1-X3 all should have the same mean, but Y should differ from any of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(X1, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(X3, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Write some code that compares the correlations of each set of variables and prints the two variables with the highest correlation.\n",
    "\n",
    "Hint: You will probably want to use two for loops (although there may also be a tricky way to do this with pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-squared test\n",
    "\n",
    "These test whether the frequency of something occurring by group is independent. So, we'll need to change Y into something that has a frequency.\n",
    "\n",
    "The following code will produce the 2 rows of a table. The first row (`large_y_counts`) is the number of large Y values by group. The second (`small_y_counts`) is the number of small y values per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_y_counts = []\n",
    "small_y_counts = []\n",
    "Y_med = np.median(Y)\n",
    "for g in ['A','B','C']:\n",
    "    large_y_count = 0\n",
    "    small_y_count = 0\n",
    "    # Instead of looping through the values, we loop through the index.\n",
    "    # That way we can use the same index (i) to the the value of `Y[i]` and\n",
    "    # the value of the `groups[i]` variable\n",
    "    for i in range(len(Y)):\n",
    "        if group[i] == g:\n",
    "            if Y[i] > Y_med:\n",
    "                large_y_count += 1\n",
    "            else:\n",
    "                small_y_count += 1\n",
    "    large_y_counts.append(large_y_count)\n",
    "    small_y_counts.append(small_y_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like many things, this could be done more quickly with pandas\n",
    "df['large_y'] = df.Y > df.Y.median()\n",
    "\n",
    "large_y_counts = df.loc[df.large_y==True,:].groupby('group').Y.count()\n",
    "small_y_counts = df.loc[df.large_y==False,:].groupby('group').Y.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we call the Chi-squared test\n",
    "stats.chi2_contingency([large_y_counts, small_y_counts])\n",
    "# This returns the Chi-square value, a p-value, degrees of freedom, and the expected counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA\n",
    "\n",
    "This tests whether the means of multiple groups have the same population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these all should\n",
    "stats.f_oneway(X1,X2,X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but adding Y should change it\n",
    "\n",
    "stats.f_oneway(X1,X2,X3,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear regression is possible with scipy stats\n",
    "stats.linregress(X1, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but for multiple regression we need to use something else. One option is sklearn,\n",
    "# the machine learning package. Another, maybe simpler is statsmodels, which I show here:\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'X1':X1,\n",
    "                   'X2':X2,\n",
    "                   'X3': X3,\n",
    "                   'group':group,\n",
    "                   'Y':Y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sm.ols(formula=\"Y ~ X1 + X2 + X3 + group\", data=df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the benefit of regression - the coefficient for X1 is much closer to the true coefficient (1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Google to figure out how to output this table as text that you could put into a Word document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very brief intro to machine learning\n",
    "\n",
    "Per a request, I'm going to show how to run a random forest model using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# sklearn doesn't handle categorical vars, so we have to change to dummies\n",
    "rf_df = pd.get_dummies(df)\n",
    "\n",
    "Y = rf_df.pop('Y').values\n",
    "Y_train = Y[:50]\n",
    "Y_test = Y[50:]\n",
    "X_train = rf_df[:50]\n",
    "X_test = rf_df[50:]\n",
    "clf = RandomForestRegressor(n_estimators=50)\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(clf.feature_importances_, index = X_train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Think of a question in some data we've used before (crash data, Twitter data, reddit data) that a statistical test would help to answer and apply one of those covered above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
