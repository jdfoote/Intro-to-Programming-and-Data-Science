{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using APIs to Get Data From the Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**API** means Application Programmer Interface\n",
    "\n",
    "An API is a set of instructions that describe how computers can interact with each other to request and receive information.\n",
    "\n",
    "Some important questions we will ask that help us discover APIs is below.\n",
    "\n",
    "|Question | In technical terms |\n",
    "|:---------|:--------------------|\n",
    "|Where is my data? | What is the domain? |\n",
    "|How do I learn what data is available?| Where is the documentation? |\n",
    "|How do I request specific data?| How do I formulate a URL for a specific purpose? |\n",
    "|How do I interpret the data?| What is the structure and format of the output?|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's walk through an example in the browser**\n",
    "\n",
    "PlaceKitten!\n",
    "\n",
    "In a browser, go to http://www.placekitten.com\n",
    "\n",
    "|In technical terms | PlaceKitten |\n",
    "|:---------|:--------------------|\n",
    "|What is the domain? | http://www.placekitten.com |\n",
    "|Where is the documentation?| The documentation is on the home page. |\n",
    "|How do I formulate a URL for a specific purpose? | You put it in the url like http://www.placekitten/width/height |\n",
    "|What is the structure and format of the output?| It's an image! |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing placekitten in python\n",
    "\n",
    "We're going to use a special library called <code>requests</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image  # This line lets you display images. We'll use that in a bit.\n",
    "\n",
    "# This line lets you use python to download data from the web.\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a 200 by 300 image from placekitten.\n",
    "r = requests.get('http://www.placekitten.com/200/300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the status code\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the content\n",
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Image function to display the image\n",
    "display(Image(r.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Write a function that takes in the width and height and prints an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Can you write a loop to show several images?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a loop that shows multiple images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Getting World Times\n",
    "\n",
    "This example introduces a slightly more complicated API. It also introduces **JSON** which is a very common data format.\n",
    "\n",
    "The API (including some documentation) is at http://worldtimeapi.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download list of time zones\n",
    "r = requests.get(\"http://worldtimeapi.org/api/timezone\")\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Use the .json() function to get the response converted to a dictionary or list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the .json() function to get the response converted to a dictionary or list\n",
    "# What did it return?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Get the time for your time zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Get the time for your IP address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the time for your IP address\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Getting Wikipedia pages\n",
    "\n",
    "Wikipedia also has an open API, and I want to use it to show one other tip for using the `requests` library; many APIs will take in a set of parameters, which you can pass as a parameter dictionary.\n",
    "\n",
    "The documentation for the very extensive API is [here](https://www.mediawiki.org/wiki/API:Main_page). Many of the operations require you to authenticate (which we will cover next), but some things, like getting the content of a page, do not.\n",
    "\n",
    "For example, the following code gets the recent changes to Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "endpt = 'https://en.wikipedia.org/w/api.php'\n",
    "\n",
    "\n",
    "def get_last_pages_changed(n):\n",
    "    params = {'action': 'query',\n",
    "          'format': 'json',\n",
    "          'list': 'recentchanges',\n",
    "          'rcnamespace': '0',\n",
    "          'rclimit': n}\n",
    "    r = requests.get(endpt, params=params)\n",
    "    #print(r.json())\n",
    "    #print(r.json()['query']['recentchanges'])\n",
    "    result = []\n",
    "    content = r.json()['query']['recentchanges']\n",
    "    for page in content:\n",
    "        result.append(page['title'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "\n",
    "Review the documentation (and Google) to see if you can figure out how to get a list of all of the users who have ever edited the most recently edited Wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here\n",
    "\n",
    "def get_editors(title):\n",
    "    params = {'action':'query',\n",
    "         'prop':'revisions',\n",
    "         'titles': title,\n",
    "              'format': 'json',\n",
    "          'rvlimit': 500,\n",
    "          'rvprop': 'user|timestamp'\n",
    "         }\n",
    "    r = requests.get(endpt, params=params)\n",
    "    print(r.json())\n",
    "    \n",
    "get_editors('Purdue University')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4: Intro to Twitter API\n",
    "\n",
    "In order to use the Twitter API, you need to do two things:\n",
    "\n",
    "1. Install tweepy. This is a python library designed to make it easier to use the API (rather than using `requests` directly. I made [this video](https://www.youtube.com/watch?v=TASX3evcgG4) to walk you through how to install tweepy in Anaconda.\n",
    "\n",
    "2. To use the Twitter API, you need to be authenticated, and so you need a developer account. [This page](https://wiki.communitydata.science/Intro_to_Programming_and_Data_Science_(Summer_2020)/Twitter_authentication_setup) explains how to get a developer account.\n",
    "\n",
    "Once you have your keys, you should create a file called `twitter_authentication.py` in the same directory as this file. It should contain the following line (replace the fake string below with the corresponding key from your twitter account):\n",
    "\n",
    "```\n",
    "BEARER_TOKEN = 'oxVSzC1OjXOVVYrBvGyy6XKKe772Jdvvw6Opb3bSLdIb'\n",
    "```\n",
    "\n",
    "In general, it is a good practice to keep your keys (which should be secret) separate from your code, which you can share. In this case, we put them in a different file and then import them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads the tweepy library and imports these keys from the `twitter_authentication.py` file, and then prepares to \"log in\" to your account for the Twitter API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "from twitter_authentication import BEARER_TOKEN\n",
    "\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rate Limiting\n",
    "\n",
    "You will quickly learn that the Twitter API is \"rate limited\". This means that they will only let each account make a certain number of calls to their API in a given time period. The default rate is quite low - many calls only allow 15 calls per 15 minutes.\n",
    "\n",
    "You may notice above that we had the code:\n",
    "```\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "```\n",
    "the `wait_on_rate_limit=True` tells your code to wait for 15 minutes if it gets back a message that you've exceeded a rate limit. This can get annoying when debugging, so be careful with how often you try things - sometimes it makes sense, for example, to try to get a small amount of data that only takes one call and make sure that your code works before trying to get all of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by getting the last 20 tweets from the @LifeAtPurdue account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "puid = client.get_user(username='LifeAtPurdue').data.id\n",
    "tweets = client.get_users_tweets(puid, max_results=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweepy stores the tweets in `.data`, so this loops through all of them and prints the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#PurdueUniversity President Mitch Daniels will sit down with serial entrepreneur and philanthropist @JTLonsdale,  general manager of venture capital firm @8vc, to discuss his innovation, investing and more. The Presidential Lecture Series event is Nov. 16. https://t.co/BwuIzTV5TJ\n",
      "Computer chips are the brains that power all modern electronics but as their demand skyrockets, so does the demand for a trained workforce to design, test and develop them. #Purdue's answer: graduate 1,000 semiconductor engineers annually. https://t.co/3kDoPwxM5q\n",
      "“Everything Tyler wrote about, I could relate to. We’ve had so many things in common, from types of radiation and chemotherapy to all that we’ve felt throughout these journeys.” — Eric Magallanes, winner of the 2022 Tyler Trent Award. Get to know Eric. ⬇️ https://t.co/B4GtHBmMoe\n",
      "“Being named a Brand That Matters reflects delivering on that promise, for today and tomorrow.” #FCBrandAwards Learn more: https://t.co/7iY0WDnLdZ\n",
      "“Purdue has positioned itself as a brand and university that holds itself accountable to the real purpose under which it was created: a land-grant institution for the people of Indiana and the entire country,” said Shawn Taylor, the newest appointee to the Purdue trustees.\n",
      "For the 2nd year in a row, #Purdue has been named to @FastCompany’s list of Brands That Matter. https://t.co/0VH1NJEXmv\n",
      "@resources_david Thank you for reaching out Undergraduate Admissions office can assist you with your question. #Boilerup! -----https://t.co/BqRLMVIQBR\n",
      "@RKRelentless @PurdueLibArts We are so proud of our Boilermakers! 🚂\n",
      "It's the kick-off to #ThisIsPurdue’s ‘Countdown to Halloween.' 🎃 Join the #podcast team at @CulverAcademies and check out TikTok superstar Phil Cook's (@chemteacherphil) viral #Halloween experiments, including an exploding pumpkin and flaming candy corn. https://t.co/5HokzzJEJh https://t.co/xXAxMCbequ\n",
      "Hats off to @AmericanAir for innovative, inclusive thinking!\n",
      "\n",
      "In higher ed, @PurdueGlobal helped 2 men use their real-world flight experience to complete their bachelors' in professional flight in about 1 year.\n",
      "https://t.co/QHUcaX7pT0 https://t.co/58l3uJM7GG\n",
      "Unlike humans, drones lack ways to filter out info they don’t need, which slows down their response time to changes in their environment. Learn how inspiration from a to-go cup lid may help a drone to detect dangerous conditions faster. #PurdueInnovation https://t.co/aguFxUGoHA\n",
      "Pharmaceutical leader @LillyPad is committing $92.5 million to #PurdueUniversity to establish an innovative pharmaceutical manufacturing scholarship program and extend its strategic research collaboration with Purdue. #PurdueInnovation https://t.co/ewBcw6KMDf\n",
      "RT @REthanBraden: “@LifeAtPurdue is dedicated to making a quality higher education accessible. It has frozen tuition for 11 years in a row,…\n",
      "Know those small domes you press on a to-go cup lid? They may one day save a winged drone from a nosedive, a new #PurdueUniversity study suggests. #PurdueInnovation https://t.co/aguFxUY06a\n",
      "What does Alpha Phi Alpha Fraternity, Inc. mean to Nigel Taylor? It means community, brotherhood and finding his fit at #PurdueUniversity. #NPHC\n",
      "\n",
      "Watch more of his story. https://t.co/MJqRLI9URq https://t.co/xVVFaya3lj\n",
      "Join leading technology entrepreneur and investor @JTLonsdale and #PurdueUniversity President Mitch Daniels at next Presidential Lecture Series event on Nov. 16 in Stewart Center’s Fowler Hall. https://t.co/BwuIzUcGLh\n",
      "Borrowing a shape from a to-go cup lid, a drone wing could learn how to sense danger faster. #PurdueInnovation https://t.co/aguFxUY06a\n",
      "The U.S. needs at least 50,000 new semiconductor engineers over the next five years to staff planned factories and research labs. #Purdue will play a crucial role in this massive workforce development undertaking. https://t.co/3kDoPwxM5q\n",
      "@JeromeAdamsMD Thank you for sharing, Boiler Up!🚂🆙\n",
      "@reesecup0374 @FastCompany Thank you for sharing, Boiler Up!🚂🆙\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets.data:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, tweet objects only contain their ID and the text of the tweet, but there's a lot more information you can ask for.\n",
    "\n",
    "For example, this gets information about what the tweet is replying to and some metrics (retweets, likes, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = client.get_users_tweets(puid, max_results=20, tweet_fields=['created_at', 'public_metrics', 'referenced_tweets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are also kind of hidden within each tweet object, so this is how we might gather them into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for tweet in tweets.data:\n",
    "    curr_result = {'text': tweet.text,\n",
    "                   'id': tweet.id,\n",
    "                   'retweets': tweet.public_metrics['retweet_count'],\n",
    "                   'replies': tweet.public_metrics['reply_count'],\n",
    "                   'created_time': tweet.created_at\n",
    "                  }\n",
    "    result.append(curr_result)\n",
    "    \n",
    "df = pd.DataFrame(result)\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#PurdueUniversity President Mitch Daniels will...</td>\n",
       "      <td>1586011926013906948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-28 15:08:04+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computer chips are the brains that power all m...</td>\n",
       "      <td>1585772583257083904</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-27 23:17:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“Everything Tyler wrote about, I could relate ...</td>\n",
       "      <td>1585738162231459841</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-27 21:00:14+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“Being named a Brand That Matters reflects del...</td>\n",
       "      <td>1585723242203213825</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-27 20:00:56+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Purdue has positioned itself as a brand and u...</td>\n",
       "      <td>1585723179003432960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-27 20:00:41+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>For the 2nd year in a row, #Purdue has been na...</td>\n",
       "      <td>1585723065169764362</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-10-27 20:00:14+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@resources_david Thank you for reaching out Un...</td>\n",
       "      <td>1585685689353572358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-27 17:31:43+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@RKRelentless @PurdueLibArts We are so proud o...</td>\n",
       "      <td>1585681498564444161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-27 17:15:04+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It's the kick-off to #ThisIsPurdue’s ‘Countdow...</td>\n",
       "      <td>1585677923650093056</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-27 17:00:52+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hats off to @AmericanAir for innovative, inclu...</td>\n",
       "      <td>1585666412437184513</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-27 16:15:07+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Unlike humans, drones lack ways to filter out ...</td>\n",
       "      <td>1585647719359467521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-27 15:00:50+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pharmaceutical leader @LillyPad is committing ...</td>\n",
       "      <td>1585632554136137728</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-27 14:00:35+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RT @REthanBraden: “@LifeAtPurdue is dedicated ...</td>\n",
       "      <td>1585606816037314560</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-27 12:18:18+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Know those small domes you press on a to-go cu...</td>\n",
       "      <td>1585381255897645072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-26 21:22:01+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What does Alpha Phi Alpha Fraternity, Inc. mea...</td>\n",
       "      <td>1585371957473722369</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-26 20:45:04+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Join leading technology entrepreneur and inves...</td>\n",
       "      <td>1585344766127919104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-26 18:57:01+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Borrowing a shape from a to-go cup lid, a dron...</td>\n",
       "      <td>1585327663857778698</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-26 17:49:03+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The U.S. needs at least 50,000 new semiconduct...</td>\n",
       "      <td>1585296715942436864</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-26 15:46:05+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@JeromeAdamsMD Thank you for sharing, Boiler U...</td>\n",
       "      <td>1585287491292217345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-26 15:09:25+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@reesecup0374 @FastCompany Thank you for shari...</td>\n",
       "      <td>1585286593773985793</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-26 15:05:51+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text                   id  \\\n",
       "0   #PurdueUniversity President Mitch Daniels will...  1586011926013906948   \n",
       "1   Computer chips are the brains that power all m...  1585772583257083904   \n",
       "2   “Everything Tyler wrote about, I could relate ...  1585738162231459841   \n",
       "3   “Being named a Brand That Matters reflects del...  1585723242203213825   \n",
       "4   “Purdue has positioned itself as a brand and u...  1585723179003432960   \n",
       "5   For the 2nd year in a row, #Purdue has been na...  1585723065169764362   \n",
       "6   @resources_david Thank you for reaching out Un...  1585685689353572358   \n",
       "7   @RKRelentless @PurdueLibArts We are so proud o...  1585681498564444161   \n",
       "8   It's the kick-off to #ThisIsPurdue’s ‘Countdow...  1585677923650093056   \n",
       "9   Hats off to @AmericanAir for innovative, inclu...  1585666412437184513   \n",
       "10  Unlike humans, drones lack ways to filter out ...  1585647719359467521   \n",
       "11  Pharmaceutical leader @LillyPad is committing ...  1585632554136137728   \n",
       "12  RT @REthanBraden: “@LifeAtPurdue is dedicated ...  1585606816037314560   \n",
       "13  Know those small domes you press on a to-go cu...  1585381255897645072   \n",
       "14  What does Alpha Phi Alpha Fraternity, Inc. mea...  1585371957473722369   \n",
       "15  Join leading technology entrepreneur and inves...  1585344766127919104   \n",
       "16  Borrowing a shape from a to-go cup lid, a dron...  1585327663857778698   \n",
       "17  The U.S. needs at least 50,000 new semiconduct...  1585296715942436864   \n",
       "18  @JeromeAdamsMD Thank you for sharing, Boiler U...  1585287491292217345   \n",
       "19  @reesecup0374 @FastCompany Thank you for shari...  1585286593773985793   \n",
       "\n",
       "    retweets  replies              created_time  \n",
       "0          0        0 2022-10-28 15:08:04+00:00  \n",
       "1          3        0 2022-10-27 23:17:00+00:00  \n",
       "2          1        0 2022-10-27 21:00:14+00:00  \n",
       "3          2        1 2022-10-27 20:00:56+00:00  \n",
       "4          1        1 2022-10-27 20:00:41+00:00  \n",
       "5          4        3 2022-10-27 20:00:14+00:00  \n",
       "6          0        0 2022-10-27 17:31:43+00:00  \n",
       "7          0        0 2022-10-27 17:15:04+00:00  \n",
       "8          8        0 2022-10-27 17:00:52+00:00  \n",
       "9          1        0 2022-10-27 16:15:07+00:00  \n",
       "10         0        0 2022-10-27 15:00:50+00:00  \n",
       "11        13        0 2022-10-27 14:00:35+00:00  \n",
       "12         2        0 2022-10-27 12:18:18+00:00  \n",
       "13         0        0 2022-10-26 21:22:01+00:00  \n",
       "14         0        0 2022-10-26 20:45:04+00:00  \n",
       "15         0        0 2022-10-26 18:57:01+00:00  \n",
       "16         2        0 2022-10-26 17:49:03+00:00  \n",
       "17         6        0 2022-10-26 15:46:05+00:00  \n",
       "18         0        0 2022-10-26 15:09:25+00:00  \n",
       "19         0        0 2022-10-26 15:05:51+00:00  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try to change the `count` argument above, and you'll quickly learn that if you raise it over 200, you will still only get 200 tweets. If you want to print more than 200 tweets, you may need to use a [cursor](http://docs.tweepy.org/en/v3.5.0/cursor_tutorial.html).\n",
    "\n",
    "This is basically tweepy's clever way of breaking what you want to do into multiple calls to the API.\n",
    "\n",
    "For example, this call will get 350 tweets. The `count` argument (optional) says how many tweets to get per call, and the argument in `.items()` is how many to get in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweepy.Cursor(api.home_timeline, count = 175).items(350):\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Followers\n",
    "\n",
    "You can also get information about a user, such as who their followers are.\n",
    "\n",
    "Here's information about me and some of my followers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = api.get_user(screen_name = 'jdfoote')\n",
    "\n",
    "print(user.screen_name + \" has \" + str(user.followers_count) + \" followers.\")\n",
    "\n",
    "print(\"They include these 100 people:\")\n",
    "\n",
    "for follower in user.followers(count=100):\n",
    "    print(follower.screen_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what that user object looks like for my user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user._json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the user object for one of my followers, which is nearly identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follower._json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that 200 is the maximum number of followers that you can get at one time. If you want to get information about all of a user's followers, you will need to use a cursor. If you are getting many followers, you will almost certainly hit rate limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for follower in tweepy.Cursor(api.get_followers, screen_name='jdfoote', count=200).items():\n",
    "    #print(follower.screen_name)\n",
    "    f.append(follower.screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching\n",
    "\n",
    "For most of your research, you may be interested in how people are talking about a given topic. There are two main ways to do this.\n",
    "\n",
    "The first is the search API ([Official Twitter info on the Search API](https://developer.twitter.com/en/docs/tweets/search/overview)). We only have access to \"[Standard Search](https://developer.twitter.com/en/docs/tweets/search/overview/standard)\", the most limited of Twitter Search API options, which is limited to the last 7 days.\n",
    "\n",
    "\n",
    "**Note that if you would like to use Twitter for a project or a paper, you can request access to the Academic Research API, which includes historical search and a much higher limit on the number of tweets you can request**\n",
    "\n",
    "Unforutnately, tweepy doesn't yet support the v2 API for Twitter, but [here is an example of how to use it](https://github.com/twitterdev/Twitter-API-v2-sample-code/blob/master/Full-Archive-Search/full-archive-search.py) with just requests.\n",
    "\n",
    "\n",
    "[This page](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets) is the documentation for Standard Search and has some helpful intel about modifying the parameters.\n",
    "\n",
    "Below is a simple example that gets the last 20 tweets about data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_tweets = api.search_tweets('\"from:@jdfoote\"', count=20)\n",
    "\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.user.screen_name + \"\\t\" + str(tweet.created_at) + \"\\t\" + tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that many of these results are truncated. If you want the full tweet, you actually have to modify the call a little bit, like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_tweets = api.search_tweets('\"data science\"', count=20, tweet_mode='extended')\n",
    "\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.user.screen_name + \"\\t\" + str(tweet.created_at) + \"\\t\" + tweet.full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Search resources\n",
    "\n",
    "* [Tweepy extended tweets documentation](http://docs.tweepy.org/en/latest/extended_tweets.html)\n",
    "* [Twitter documentation for crafting queries](https://developer.twitter.com/en/docs/tweets/search/guides/standard-operators). This includes things like how to search by geography or remove retweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "The other option is to \"stream\" tweets. Instead of looking backward, this just keeps you connected to Twitter and whenever new tweets come in, they are sent to your program. You would typicaly just keep the program running and keep writing the data that you want to an external file.\n",
    "\n",
    "As with the search API, there are some caveats. One is that (I believe) there is no guarantee that this is all of the tweets that match. If you try to filter by very popular terms, then Twitter may give you only a sample of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Streamer(tweepy.Stream):\n",
    "    def on_status(self, tweet):\n",
    "        print(tweet.author.screen_name + \"\\t\" + tweet.text)\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        print( 'Error: ' + repr(status_code))\n",
    "        return False\n",
    "\n",
    "streamer = Streamer(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "keywords = ['Purdue', '\"data science\"']\n",
    "streamer.filter(track = keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "\n",
    "7. Use the streaming API to produce a list of 1000 tweets about a topic.\n",
    "2. From that list of 1000 tweets, eliminate retweets.\n",
    "4. For each original tweet, create a dictionary with the number of times you see it retweeted in your dataset.\n",
    "5. Get a list of the URLs in your dataset\n",
    "3. Now, see if you can figure out how to eliminate retweets in the query instead.\n",
    "7. Get the last 50 tweets from West Lafayette, using the search API. (Hint - look up the geocode information [here](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets)).\n",
    "8. Alter the streaming algorithm to include a \"locations\" filter to get tweets from New York City. You need to use the order sw_lng, sw_lat, ne_lng, ne_lat for the four coordinates instead of a radius as in the search API.\n",
    "\n",
    "### BONUS Questions\n",
    "1. For each of your followers, get *their* followers (investigate time.sleep to throttle your computation)\n",
    "2. Identify the follower you have that also follows the most of your followers.\n",
    "3. How many users follow you but none of your followers?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teaching",
   "language": "python",
   "name": "teaching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
