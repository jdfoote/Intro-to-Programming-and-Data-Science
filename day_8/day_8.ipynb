{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using APIs to Get Data From the Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**API** means Application Programmer Interface\n",
    "\n",
    "An API is a set of instructions that describe how computers can interact with each other to request and receive information.\n",
    "\n",
    "Some important questions we will ask that help us discover APIs is below.\n",
    "\n",
    "|Question | In technical terms |\n",
    "|:---------|:--------------------|\n",
    "|Where is my data? | What is the domain? |\n",
    "|How do I learn what data is available?| Where is the documentation? |\n",
    "|How do I request specific data?| How do I formulate a URL for a specific purpose? |\n",
    "|How do I interpret the data?| What is the structure and format of the output?|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's walk through an example in the browser**\n",
    "\n",
    "PlaceKitten!\n",
    "\n",
    "In a browser, go to http://www.placekitten.com\n",
    "\n",
    "|In technical terms | PlaceKitten |\n",
    "|:---------|:--------------------|\n",
    "|What is the domain? | http://www.placekitten.com |\n",
    "|Where is the documentation?| The documentation is on the home page. |\n",
    "|How do I formulate a URL for a specific purpose? | You put it in the url like http://www.placekitten/width/height |\n",
    "|What is the structure and format of the output?| It's an image! |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing placekitten in python\n",
    "\n",
    "We're going to use a special library called <code>requests</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image  # This line lets you display images. We'll use that in a bit.\n",
    "\n",
    "# This line lets you use python to download data from the web.\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a 200 by 300 image from placekitten.\n",
    "r = requests.get('http://www.placekitten.com/200/300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the status code\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the content\n",
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Image function to display the image\n",
    "display(Image(r.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Write a function that takes in the width and height and prints an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Can you write a loop to show several images?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a loop that shows multiple images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Getting World Times\n",
    "\n",
    "This example introduces a slightly more complicated API. It also introduces **JSON** which is a very common data format.\n",
    "\n",
    "The API (including some documentation) is at http://worldtimeapi.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download list of time zones\n",
    "r = requests.get(\"http://worldtimeapi.org/api/timezone\")\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Use the .json() function to get the response converted to a dictionary or list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the .json() function to get the response converted to a dictionary or list\n",
    "# What did it return?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Get the time for your time zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Get the time for your IP address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the time for your IP address\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Getting Wikipedia pages\n",
    "\n",
    "Wikipedia also has an open API, and I want to use it to show one other tip for using the `requests` library; many APIs will take in a set of parameters, which you can pass as a parameter dictionary.\n",
    "\n",
    "The documentation for the very extensive API is [here](https://www.mediawiki.org/wiki/API:Main_page). Many of the operations require you to authenticate (which we will cover next), but some things, like getting the content of a page, do not.\n",
    "\n",
    "For example, the following code gets the recent changes to Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "endpt = 'https://en.wikipedia.org/w/api.php'\n",
    "\n",
    "\n",
    "def get_last_pages_changed(n):\n",
    "    params = {'action': 'query',\n",
    "          'format': 'json',\n",
    "          'list': 'recentchanges',\n",
    "          'rcnamespace': '0',\n",
    "          'rclimit': n}\n",
    "    r = requests.get(endpt, params=params)\n",
    "    #print(r.json())\n",
    "    #print(r.json()['query']['recentchanges'])\n",
    "    result = []\n",
    "    content = r.json()['query']['recentchanges']\n",
    "    for page in content:\n",
    "        result.append(page['title'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_last_pages_changed(n = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "\n",
    "Review the documentation (and Google) to see if you can figure out how to get a list of the last users who edited the most recently edited Wikipedia page.\n",
    "\n",
    "The function below will get you partway there. It takes in an article name, and give you the last edits.\n",
    "\n",
    "You should:\n",
    "* Use the get_last_pages_changed function and extract the last page changed\n",
    "* Use the get_edits function to get the last edits of that page\n",
    "* Extract the user names from the edits and make a list of them\n",
    "\n",
    "### Bonus challenge\n",
    "\n",
    "If you are feeling really courageous, figure out how to get all of the edits/editors for a page, not just the last 500.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here\n",
    "\n",
    "def get_edits(title):\n",
    "    params = {'action':'query',\n",
    "         'prop':'revisions',\n",
    "         'titles': title,\n",
    "              'format': 'json',\n",
    "          'rvlimit': 500,\n",
    "          'rvprop': 'user|timestamp'\n",
    "         }\n",
    "    r = requests.get(endpt, params=params)\n",
    "    print(r.json())\n",
    "    \n",
    "get_edits('Purdue University')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4: Intro to Reddit API\n",
    "\n",
    "## Setup\n",
    "In order to use the Reddit API, you need to do two things:\n",
    "\n",
    "1. Install [PRAW](https://praw.readthedocs.io/en/stable/) (the Python Reddit API Wrapper). This is a python library designed to make it easier to use the API (rather than using `requests` directly).\n",
    "\n",
    "You can install PRAW in the terminal using `conda install -c conda-forge praw` or `pip install praw`\n",
    "\n",
    "2. To use the Reddit API, you need to be authenticated, and so you need a Reddit account. You also need to create an app. [This page](https://wiki.communitydata.science/Intro_to_Programming_and_Data_Science_(Fall_2023)/Reddit_authentication_setup) explains how to get a developer account, create an app, and get the `client_id` and `client_secret`.\n",
    "\n",
    "Once you have your client keys, you should create a file called `reddit_authentication.py` in the same directory as this file. It should contain the following (replace the fake strings below with the corresponding info from your Reddit app):\n",
    "\n",
    "```\n",
    "client_id = \"_anb-dsxipuqf7jA9wzeMqZ\"\n",
    "client_secret = \"4kXxiBOFdPY1HBw4843sgm6oiTYbWkFgz\"\n",
    "user_agent = \"python:COM 674 class project:v1.0 (by /u/yourusername)\"\n",
    "username = \"yourusername\"\n",
    "password = \"yourpassword\"\n",
    "```\n",
    "\n",
    "In general, it is a good practice to keep your keys (which should be secret) separate from your code, which you can share. In this case, we put them in a different file and then import them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PRAW\n",
    "\n",
    "When using PRAW, we need to authenticate. For more complicated APIs, like the Reddit API, it's important for the server to know who is makin the request, so they know what information to receive. Authentication means proving you are who you say you are.\n",
    "\n",
    "In PRAW, we create a `Reddit` object, which handles authentication and other things. It's basically creating an authenticated session, similar to when you log into a website.\n",
    "\n",
    "Here, we'll import the PRAW library and our authentication info from the reddit_authenticaton file. Note that there are some things you can do with the API without authenticating, but the rate limit is much higher if you are authenticated. (100 queries per minute vs 10 queries per minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import reddit_authentication\n",
    "\n",
    "# Create an instance called reddit. We'll use this to call the API.\n",
    "reddit = praw.Reddit(client_id=reddit_authentication.client_id,\n",
    "                     client_secret=reddit_authentication.client_secret,\n",
    "                    user_agent = reddit_authentication.user_agent,\n",
    "                    username = reddit_authentication.username,\n",
    "                    password = reddit_authentication.password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Reddit API is powerful and complicated. We'll just do a few simple things here.\n",
    "\n",
    "The [full documentation is here](https://praw.readthedocs.io/en/stable/) if you want to explore more.\n",
    "\n",
    "For now, we'll show how to get the top subreddits on a topic, and how to explore the comments from a given subreddit.\n",
    "\n",
    "First, let's find the top 10 Purdue-related subreddits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The top 10 Purdue-related subreddits, according to reddit's search\n",
    "top_purdue_subs = [x for x in reddit.subreddits.search('Purdue')][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in top_purdue_subs:\n",
    "    print(f\"Name: {s.display_name}\\t\\tSubscribers: {s.subscribers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the `.display_name` and `.subscribers` attributes of the subreddits. To see what is part of an object (like these subreddit objects), you can use the `dir` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(top_purdue_subs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our small project\n",
    "\n",
    "Let's say that our goal is to identify the redditors who have been most active recently on the Purdue subreddit, and to see what other subreddits they are active on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commenters = {}\n",
    "\n",
    "for comment in reddit.subreddit('Purdue').comments(limit=3000):\n",
    "    if comment.author in commenters:\n",
    "        commenters[comment.author] += 1\n",
    "    else:\n",
    "        commenters[comment.author] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when we look at our dictionary, we actually saved all of the Redditor objects for the authors. This makes it a little bit simpler to get information about those users later, but we could have also saved their usernames instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commenters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises 7 and 8\n",
    "\n",
    "7. Improve my code above so that it only gets comments if they have a positive score.\n",
    "\n",
    "8. See if you can figure out how to get the \"comment karma\" for each of the users in our dictionary, and print out the top 10 users by comment karma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the top users by number of comments\n",
    "\n",
    "Ok, so let's look at the top 100 users by the number of comments posted. We can do this a few ways. One way is to use the `sorted` function on a dictionary. This will sort the keys of the dictionary by the value of the dictionary. We can then use the `reverse` parameter to sort in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort commenters dictionary by value\n",
    "sorted_commenters = sorted(commenters.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_commenters[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_commenters = sorted_commenters[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I happen to know that AutoModerator is a bot, so let's remove that from our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_commenters = top_commenters[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the top subreddits that our users are active on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = {}\n",
    "\n",
    "for commenter in top_commenters:\n",
    "    user = commenter[0]\n",
    "    # Get the user's 100 most recent comments\n",
    "    for comment in user.comments.new(limit=100):\n",
    "        subreddit = comment.subreddit.display_name\n",
    "        if subreddit == 'Purdue':\n",
    "            continue\n",
    "        if subreddit in subreddits:\n",
    "            subreddits[subreddit] += 1\n",
    "        else:\n",
    "            subreddits[subreddit] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on rate limits\n",
    "\n",
    "You may have noticed that that took a long time. That's because we are making a lot of requests to the Reddit API. The Reddit API has a rate limit of 100 requests per minute. If you go over the limit, then Reddit sends you a message asking you to wait. PRAW actually handles this without our intervention, but it does mean that it's hard to tell how long things will take. One approach is to at least print out the commenter name, for example, so you can tell how quickly the queries are running. If they are going too slowly, then you may want to change the limits. For example, we got 100 comments per user in this code, but that may take multiple queries, so reducing that number could speed things up.\n",
    "\n",
    "When using other libraries, including `requests`, you will often have to write code to handle rate limits yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting the subreddits\n",
    "\n",
    "Let's just do the same thing we did before, but this time sort the subreddits by the number of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_subreddits = sorted(subreddits.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_subreddits[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9 (Challenge Exercise)\n",
    "\n",
    "Instead of storing the number of total comments per subreddit, store the number of our top_commenters who contribute to each subreddit. In other words, if User A comments on Subreddit A twice, my code counts that twice. Instead, I want to count that only once.\n",
    "\n",
    "Hint: This is tricky. One approach would be to make a list of subreddits that each commenter has commented in, and then change that into a set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Exercises\n",
    "\n",
    "10. Get the last comments across all subreddits. Figure out which subreddits were most actively commented in.\n",
    "11. Get the last comments across all subreddits. Figure out which users were most active.\n",
    "12. Find the top 5 posts on the Purdue subreddit over the last year ([HINT](https://praw.readthedocs.io/en/stable/code_overview/models/subreddit.html#praw.models.Subreddit.top)). Get all of the comments for each of those posts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teaching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
